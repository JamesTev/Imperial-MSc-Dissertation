@misc{bci-wolpaw,
	author = 	 {Jonathan R. Wolpaw and Niels Birbaumer and Dennis J. McFarland and Gert Pfurtscheller and Theresa M. Vaughan},
	year = 	 {2002},
	title = 	 {Brain–computer interfaces for communication and control},
	journal = 	 {Clinical Neurophysiology},
	volume = 	 {113},
	number = 	 {6},
	pages = 	 {767-791},
	abstract = 	 {For many years people have speculated that electroencephalographic activity or other electrophysiological measures of brain function might provide a new non-muscular channel for sending messages and commands to the external world – a brain–computer interface (BCI). Over the past 15 years, productive BCI research programs have arisen. Encouraged by new understanding of brain function, by the advent of powerful low-cost computer equipment, and by growing recognition of the needs and potentials of people with disabilities, these programs concentrate on developing new augmentative communication and control technology for those with severe neuromuscular disorders, such as amyotrophic lateral sclerosis, brainstem stroke, and spinal cord injury. The immediate goal is to provide these users, who may be completely paralyzed, or ‘locked in’, with basic communication capabilities so that they can express their wishes to caregivers or even operate word processing programs or neuroprostheses. Present-day BCIs determine the intent of the user from a variety of different electrophysiological signals. These signals include slow cortical potentials, P300 potentials, and mu or beta rhythms recorded from the scalp, and cortical neuronal activity recorded by implanted electrodes. They are translated in real-time into commands that operate a computer display or other device. Successful operation requires that the user encode commands in these signals and that the BCI derive the commands from the signals. Thus, the user and the BCI system need to adapt to each other both initially and continually so as to ensure stable performance. Current BCIs have maximum information transfer rates up to 10–25
bits/min. This limited capacity can be valuable for people whose severe disabilities prevent them from using conventional augmentative communication methods. At the same time, many possible applications of BCI technology, such as neuroprosthesis control, may require higher information transfer rates. Future progress will depend on: recognition that BCI research and development is an interdisciplinary problem, involving neurobiology, psychology, engineering, mathematics, and computer science; identification of those signals, whether evoked potentials, spontaneous rhythms, or neuronal firing rates, that users are best able to control independent of activity in conventional motor output pathways; development of training methods for helping users to gain and maintain that control; delineation of the best algorithms for translating these signals into device commands; attention to the identification and elimination of artifacts such as electromyographic and electro-oculographic activity; adoption of precise and objective procedures for evaluating BCI performance; recognition of the need for long-term as well as short-term assessment of BCI performance; identification of appropriate BCI applications and appropriate matching of applications and users; and attention to factors that affect user acceptance of augmentative technology, including ease of use, cosmesis, and provision of those communication and control capacities that are most important to the user. Development of BCI technology will also benefit from greater emphasis on peer-reviewed research publications and avoidance of the hyperbolic and often misleading media attention that tends to generate unrealistic expectations in the public and skepticism in other researchers. With adequate recognition and effective engagement of all these issues, BCI systems could eventually provide an important new communication and control option for those with motor disabilities and might also give those without disabilities a supplementary control channel or a control channel useful in special circumstances.},
	isbn = 	 {1388-2457},
	language = 	 {English},
	url = 	 {https://dx.doi.org/10.1016/S1388-2457(02)00057-3},
	doi={10.1016/S1388-2457(02)00057-3},
	pmid={12048038}
}


@article{bci-survey-nicolas-alonso,
	author={Luis Fernando Nicolas-Alonso and Jaime Gomez-Gil},
	year={2012},
	title={Brain computer interfaces, a review},
	journal={Sensors (Basel, Switzerland)},
	volume={12},
	number={2},
	pages={1211-1279},
	abstract={A brain-computer interface (BCI) is a hardware and software communications system that permits cerebral activity alone to control computers or external devices. The immediate goal of BCI research is to provide communications capabilities to severely disabled people who are totally paralyzed or 'locked in' by neurological neuromuscular disorders, such as amyotrophic lateral sclerosis, brain stem stroke, or spinal cord injury. Here, we review the state-of-the-art of BCIs, looking at the different steps that form a standard BCI: signal acquisition, preprocessing or signal enhancement, feature extraction, classification and the control interface. We discuss their advantages, drawbacks, and latest advances, and we survey the numerous technologies reported in the scientific literature to design each step of a BCI. First, the review examines the neuroimaging modalities used in the signal acquisition step, each of which monitors a different functional brain activity such as electrical, magnetic or metabolic activity. Second, the review discusses different electrophysiological control signals that determine user intentions, which can be detected in brain activity. Third, the review includes some techniques used in the signal enhancement step to deal with the artifacts in the control signals and improve the performance. Fourth, the review studies some mathematic algorithms used in the feature extraction and classification steps which translate the information in the control signals into commands that operate a computer or other device. Finally, the review provides an overview of various BCI applications that control a range of devices.},
	isbn={1424-8220},
	language={English},
	url={https://www.ncbi.nlm.nih.gov/pubmed/22438708},
	doi={10.3390/s120201211},
	pmid={22438708}
}

@misc{baillet-em-brain-mapping,
	author = 	 {S. Baillet and J. C. Mosher and R. M. Leahy},
	year = 	 {2001},
	title = 	 {Electromagnetic brain mapping},
	journal = 	 {- IEEE Signal Processing Magazine},
	volume = 	 {18},
	number = 	 {6},
	pages = 	 {14-30},
	note = 	 {ID: 1},
	isbn = 	 {1558-0792},
	doi={10.1109/79.962275}
}
@phdthesis{varnavas-phd,
	author={Andreas Soteriou Varnavas},
	year={2008},
	title={Signal Processing Methods for EEG Data Classification}
}

@article{teplan-eeg-measurement,
author = {Teplan, Michal},
year = {2002},
month = {01},
pages = {},
title = {Fundamental of EEG Measurement},
volume = {2},
journal = {MEASUREMENT SCIENCE REVIEW}
}

@report{Fernandez-Fraga2016,
   abstract = {Recently, brain computer interface (BCI) research has increased because of its application value in neural engineering and neuroscience, BCI Systems can provide online communication between a human or animal brain and external devices without depending on the normal output pathways of peripheral nerves and muscles. BCI applications include communication devices for disabled people, neuroprotheses and games. The most popular BCIs is based on steady state visual evoked potential (SSVEP) that can be recognized through detecting the dominant frequency components in the recorded electroencephalography (EEG) signals. BCI performance depends on correctly and fast decoding the user intentions and is critical to employ a reliable signal processing methods to detect and extract the components of de EEG signals recording. In this paper, mathematical tools used to design brain computer interface (BCI) systems based on electroencephalogram (EEG) signals obtain by visual stimulus are reviewed.},
   author = {S M Fernandez-Fraga and M A Aceves-Fernandez and J C Pedraza-Ortega and S Tovar-Arriaga},
   keywords = {Brain Computer Interface, BCI,EEG Signal Analysis,Steady State Visual Evoked Potential, SSVEP},
   title = {EEG Signal Analysis Methods Based on Steady State Visual Evoked Potential Stimuli for the Development of Brain Computer Interfaces: A Review Fernandez-Fraga et al ISSN 2349-7238},
   url = {www.pubicon.co.in},
}

@article{Zhu2021,
   abstract = {Brain-computer interfaces (BCIs) provide humans a new communication channel by encoding and decoding brain activities. Steady-state visual evoked potential (SSVEP)-based BCI stands out among many BCI paradigms because of its non-invasiveness, little user training, and high information transfer rate (ITR). However, the use of conductive gel and bulky hardware in the traditional Electroencephalogram (EEG) method hinder the application of SSVEP-based BCIs. Besides, continuous visual stimulation in long time use will lead to visual fatigue and pose a new challenge to the practical application. This study provides an open dataset, which is collected based on a wearable SSVEP-based BCI system, and comprehensively compares the SSVEP data obtained by wet and dry electrodes. The dataset consists of 8-channel EEG data from 102 healthy subjects performing a 12-target SSVEP-based BCI task. For each subject, 10 consecutive blocks were recorded using wet and dry electrodes, respectively. The dataset can be used to investigate the performance of wet and dry electrodes in SSVEP-based BCIs. Besides, the dataset provides sufficient data for developing new target identification algorithms to improve the performance of wearable SSVEP-based BCIs.},
   author = {Fangkun Zhu and Lu Jiang and Guoya Dong and Xiaorong Gao and Yijun Wang},
   doi = {10.3390/s21041256},
   issn = {14248220},
   issue = {4},
   journal = {Sensors (Switzerland)},
   keywords = {Brain-computer interface (BCI),Dry electrode,Electroencephalogram (EEG),Open dataset,Steady-state visual evoked potential (SSVEP),Wearable BCI},
   month = {2},
   pages = {1-17},
   publisher = {MDPI AG},
   title = {An open dataset for wearable ssvep-based brain-computer interfaces},
   volume = {21},
   year = {2021},
}
@article{Acampora2021,
   author = {Giovanni Acampora and Pasquale Trinchese and Autilia Vitiello},
   doi = {10.1016/j.dib.2021.106826},
   issn = {23523409},
   journal = {Data in Brief},
   month = {4},
   pages = {106826},
   publisher = {Elsevier BV},
   title = {A dataset of EEG signals from a single-channel SSVEP-based brain computer interface},
   volume = {35},
   year = {2021},
}
@article{Chen2017,
   abstract = {A promising approach for brain-computer interfaces (BCIs) employs the steady-state visual evoked potential (SSVEP) for extracting control information. Main advantages of these SSVEP BCIs are a simple and low-cost setup, little effort to adjust the system parameters to the user and comparatively high information transfer rates (ITR). However, traditional frequency- coded SSVEP BCIs require the user to gaze directly at the selected flicker stimulus, which is liable to cause fatigue or even photic epileptic seizures. The spatially coded SSVEP BCI we present in this article addresses this issue. It uses a single flicker stimulus that appears always in the extrafoveal field of view, yet it allows the user to control four control channels. We demonstrate the embedding of this novel SSVEP stimulation paradigm in the user interface of an online BCI for navigating a 2-dimensional computer game. Offline analysis of the training data reveals an average classification accuracy of 96.9-1.64\%, corresponding to an information transfer rate of 30.1-1.8 bits/min. In online mode, the average classification accuracy reached 87.9-11.4\%, which resulted in an ITR of 23.8-6.75 bits/min. We did not observe a strong relation between a subject's offline and online performance. Analysis of the online performance over time shows that users can reliably control the new BCI paradigm with stable performance over at least 30 minutes of continuous operation.},
   author = {Jingjing Chen and Dan Zhang and Andreas K. Engel and Qin Gong and Alexander Maye},
   doi = {10.1371/journal.pone.0178385},
   issn = {19326203},
   issue = {5},
   journal = {PLoS ONE},
   month = {5},
   pmid = {28562624},
   publisher = {Public Library of Science},
   title = {Application of a single-flicker online SSVEP BCI for spatial navigation},
   volume = {12},
   url = {/pmc/articles/PMC5451069/ /pmc/articles/PMC5451069/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5451069/},
   year = {2017},
}
@article{Xie2016,
   abstract = {Steady-State Visual Evoked Potentials (SSVEPs) are widely used in spatial selective attention. In this process the two kinds of visual simulators, Light Emitting Diode (LED) and Liquid Crystal Display (LCD), are commonly used to evoke SSVEP. In this paper, the differences of SSVEP caused by these two stimulators in the study of spatial selective attention were investigated. Results indicated that LED could stimulate strong SSVEP component on occipital lobe, and the frequency of evoked SSVEP had high precision and wide range as compared to LCD. Moreover a significant difference between noticed and unnoticed frequencies in spectrum was observed whereas in LCD mode this difference was limited and selectable frequencies were also limited. Our experimental finding suggested that average classification accuracies among all the test subjects in our experiments were 0.938 and 0.853 in LED and LCD mode, respectively. These results indicate that LED simulator is appropriate for evoking the SSVEP for the study of spatial selective attention.},
   author = {Songyun Xie and Chang Liu and Klaus Obermayer and Fangshi Zhu and Linan Wang and Xinzhou Xie and Wei Wang},
   doi = {10.1155/2016/6410718},
   issn = {16875273},
   journal = {Computational Intelligence and Neuroscience},
   pmid = {28044073},
   publisher = {Hindawi Limited},
   title = {Stimulator Selection in SSVEP-Based Spatial Selective Attention Study},
   volume = {2016},
   year = {2016},
}
@article{Sadiq2020,
   abstract = {The development of fast and robust brain–computer interface (BCI) systems requires non-complex and efficient computational tools. The modern procedures adopted for this purpose are complex which limits their use in practical applications. In this study, for the first time, and to the best of our knowledge, a successive decomposition index (SDI)-based feature extraction approach is utilized for the classification of motor and mental imagery electroencephalography (EEG) tasks. First of all, the public datasets IVa, IVb, and V from BCI competition III were denoised using multiscale principal analysis (MSPCA), and then a SDI feature was calculated corresponding to each trial of the data. Finally, six benchmark machine learning and neural network classifiers were used to evaluate the performance of the proposed method. All the experiments were performed for motor and mental imagery datasets in binary and multiclass applications using a 10-fold cross-validation method. Furthermore, computerized automatic detection of motor and mental imagery using SDI (CADMMI-SDI) is developed to describe the proposed approach practically. The experimental results suggest that the highest classification accuracy of 97.46\% (Dataset IVa), 99.52\% (Dataset IVb), and 99.33\% (Dataset V) was obtained using feedforward neural network classifier. Moreover, a series of experiments, namely, statistical analysis, channels variation, classifier parameters variation, processed and unprocessed data, and computational complexity, were performed and it was concluded that SDI is robust for noise, and a non-complex and efficient biomarker for the development of fast and accurate motor and mental imagery BCI systems.},
   author = {Muhammad Tariq Sadiq and Xiaojun Yu and Zhaohui Yuan and Muhammad Zulkifal Aziz},
   doi = {10.3390/s20185283},
   issn = {14248220},
   issue = {18},
   journal = {Sensors (Switzerland)},
   title = {Identification of motor and mental imagery EEG in two and multiclass subject-dependent tasks using successive decomposition index},
   volume = {20},
   year = {2020},
}
@inproceedings{Wang2011,
   abstract = {Moving a brain-computer interface (BCI) system from a laboratory demonstration to real-life applications still poses severe challenges to the BCI community. This study aims to integrate a mobile and wireless electroencephalogram (EEG) system and a signal-processing platform based on a cell phone into a truly wearable and wireless online BCI. Its practicality and implications in a routine BCI are demonstrated through the realization and testing of a steady-state visual evoked potential (SSVEP)-based BCI. This study implemented and tested online signal processing methods in both time and frequency domains for detecting SSVEPs. The results of this study showed that the performance of the proposed cell-phone-based platform was comparable, in terms of the information transfer rate, with other BCI systems using bulky commercial EEG systems and personal computers. To the best of our knowledge, this study is the first to demonstrate a truly portable, cost-effective and miniature cell-phone-based platform for online BCIs. © 2011 IOP Publishing Ltd.},
   author = {Yu Te Wang and Yijun Wang and Tzyy Ping Jung},
   doi = {10.1088/1741-2560/8/2/025018},
   issn = {17412560},
   issue = {2},
   journal = {Journal of Neural Engineering},
   title = {A cell-phone-based brain-computer interface for communication in daily life},
   volume = {8},
   year = {2011},
}
@inproceedings{Kanoga2020,
   abstract = {Objective. The emergence of mobile electroencephalogram (EEG) platforms have expanded the use cases of brain-computer interfaces (BCIs) from laboratory-oriented experiments to our daily life. In challenging situations where humans' natural behaviors such as head movements are unrestrained, various artifacts could deteriorate the performance of BCI applications. This paper explored the effect of muscular artifacts generated by participants' head movements on the signal characteristics and classification performance of steady-state visual evoked potentials (SSVEPs). Approach. A moving visual flicker was employed to induce not only SSVEPs but also horizontal and vertical head movements at controlled speeds, leading to acquiring EEG signals with intensity-manipulated muscular artifacts. To properly induce neck muscular activities, a laser light was attached to participants' heads to give visual feedback; the laser light indicates the direction of the head independently from eye movements. The visual stimulus was also modulated by four distinct frequencies (10, 11, 12, and 13 Hz). The amplitude and signal-to-noise ratio (SNR) were estimated to quantify the effects of head movements on the signal characteristics of the elicited SSVEPs. The frequency identification accuracy was also estimated by using well-established decoding algorithms including calibration-free and fully-calibrated approaches. Main results. The amplitude and SNR of SSVEPs tended to deteriorate when the participants moved their heads, and this tendency was significantly stronger in the vertical head movements than in the horizontal movements. The frequency identification accuracy also deteriorated in proportion to the speed of head movements. Importantly, the accuracy was significantly higher than its chance-level regardless of the level of artifact contamination and algorithms. Significance. The results suggested the feasibility of decoding SSVEPs in humans freely moving their head directions, facilitating the real-world applications of mobile BCIs.},
   author = {Suguru Kanoga and Masaki Nakanishi and Akihiko Murai and Mitsunori Tada and Atsunori Kanemura},
   doi = {10.1088/1741-2552/ab5760},
   issn = {17412552},
   issue = {1},
   journal = {Journal of Neural Engineering},
   title = {Robustness analysis of decoding SSVEPs in humans with head movements using a moving visual flicker},
   volume = {17},
   year = {2020},
}
